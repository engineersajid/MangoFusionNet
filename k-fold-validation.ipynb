{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80fa599",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-02T09:33:22.483939Z",
     "iopub.status.busy": "2025-10-02T09:33:22.483449Z",
     "iopub.status.idle": "2025-10-02T14:26:20.078892Z",
     "shell.execute_reply": "2025-10-02T14:26:20.078094Z"
    },
    "papermill": {
     "duration": 17577.912186,
     "end_time": "2025-10-02T14:26:20.392505",
     "exception": false,
     "start_time": "2025-10-02T09:33:22.480319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 09:33:24.083781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759397604.282564      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759397604.334219      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1759397619.296563      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MirroredStrategy with GPUs: [LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "Number of replicas: 1\n",
      "Detected classes: ['Amrapali', 'Banana', 'Bari 4', 'Fazli', 'GobindoBhog', 'GopalBhog', 'Harivanga', 'Himsagar', 'Khrishapat', 'Langra', 'RaniBhog', 'Sundari']\n",
      "\n",
      "===== Fold 1 =====\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759397646.145503      19 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "I0000 00:00:1759397649.583833      57 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6079 - loss: 1.3097\n",
      "Epoch 1: val_loss improved from inf to 0.54573, saving model to best_model_fold1.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 2s/step - accuracy: 0.6087 - loss: 1.3065 - val_accuracy: 0.8350 - val_loss: 0.5457 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8780 - loss: 0.3485\n",
      "Epoch 2: val_loss improved from 0.54573 to 0.16585, saving model to best_model_fold1.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 2s/step - accuracy: 0.8781 - loss: 0.3484 - val_accuracy: 0.9453 - val_loss: 0.1659 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9244 - loss: 0.2383\n",
      "Epoch 3: val_loss did not improve from 0.16585\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 2s/step - accuracy: 0.9244 - loss: 0.2382 - val_accuracy: 0.9355 - val_loss: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9417 - loss: 0.1689\n",
      "Epoch 4: val_loss improved from 0.16585 to 0.11850, saving model to best_model_fold1.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 2s/step - accuracy: 0.9417 - loss: 0.1689 - val_accuracy: 0.9583 - val_loss: 0.1185 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9498 - loss: 0.1380\n",
      "Epoch 5: val_loss improved from 0.11850 to 0.11598, saving model to best_model_fold1.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 2s/step - accuracy: 0.9498 - loss: 0.1380 - val_accuracy: 0.9641 - val_loss: 0.1160 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9659 - loss: 0.1140\n",
      "Epoch 6: val_loss did not improve from 0.11598\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 2s/step - accuracy: 0.9659 - loss: 0.1140 - val_accuracy: 0.9592 - val_loss: 0.1302 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9630 - loss: 0.1109\n",
      "Epoch 7: val_loss did not improve from 0.11598\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 2s/step - accuracy: 0.9630 - loss: 0.1109 - val_accuracy: 0.9567 - val_loss: 0.1264 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9662 - loss: 0.1050\n",
      "Epoch 8: val_loss improved from 0.11598 to 0.08263, saving model to best_model_fold1.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 2s/step - accuracy: 0.9662 - loss: 0.1051 - val_accuracy: 0.9747 - val_loss: 0.0826 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9719 - loss: 0.0910\n",
      "Epoch 9: val_loss did not improve from 0.08263\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 2s/step - accuracy: 0.9719 - loss: 0.0910 - val_accuracy: 0.9641 - val_loss: 0.1238 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9720 - loss: 0.0815\n",
      "Epoch 10: val_loss did not improve from 0.08263\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 2s/step - accuracy: 0.9720 - loss: 0.0815 - val_accuracy: 0.9706 - val_loss: 0.0982 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Fold 1 done. Test acc: 0.9657, Test loss: 0.0913\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759401205.220938      19 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6087 - loss: 1.2447\n",
      "Epoch 1: val_loss improved from inf to 0.39052, saving model to best_model_fold2.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 2s/step - accuracy: 0.6096 - loss: 1.2418 - val_accuracy: 0.8546 - val_loss: 0.3905 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8807 - loss: 0.3668\n",
      "Epoch 2: val_loss improved from 0.39052 to 0.15567, saving model to best_model_fold2.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 2s/step - accuracy: 0.8808 - loss: 0.3666 - val_accuracy: 0.9526 - val_loss: 0.1557 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9137 - loss: 0.2481\n",
      "Epoch 3: val_loss improved from 0.15567 to 0.14018, saving model to best_model_fold2.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 2s/step - accuracy: 0.9137 - loss: 0.2481 - val_accuracy: 0.9493 - val_loss: 0.1402 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9410 - loss: 0.1786\n",
      "Epoch 4: val_loss improved from 0.14018 to 0.09315, saving model to best_model_fold2.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 2s/step - accuracy: 0.9410 - loss: 0.1787 - val_accuracy: 0.9690 - val_loss: 0.0932 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9589 - loss: 0.1340\n",
      "Epoch 5: val_loss did not improve from 0.09315\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 2s/step - accuracy: 0.9590 - loss: 0.1340 - val_accuracy: 0.9428 - val_loss: 0.1711 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9609 - loss: 0.1152\n",
      "Epoch 6: val_loss did not improve from 0.09315\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9609 - loss: 0.1154 - val_accuracy: 0.9526 - val_loss: 0.1561 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9598 - loss: 0.1215\n",
      "Epoch 7: val_loss improved from 0.09315 to 0.06686, saving model to best_model_fold2.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 2s/step - accuracy: 0.9598 - loss: 0.1214 - val_accuracy: 0.9755 - val_loss: 0.0669 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9667 - loss: 0.1076\n",
      "Epoch 8: val_loss did not improve from 0.06686\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 2s/step - accuracy: 0.9667 - loss: 0.1076 - val_accuracy: 0.9567 - val_loss: 0.1110 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9631 - loss: 0.1054\n",
      "Epoch 9: val_loss did not improve from 0.06686\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 2s/step - accuracy: 0.9631 - loss: 0.1053 - val_accuracy: 0.9779 - val_loss: 0.0785 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9731 - loss: 0.0865\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.06686\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 2s/step - accuracy: 0.9731 - loss: 0.0865 - val_accuracy: 0.9730 - val_loss: 0.0703 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Fold 2 done. Test acc: 0.9528, Test loss: 0.1431\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759404636.776091      19 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6236 - loss: 1.2178\n",
      "Epoch 1: val_loss improved from inf to 0.43461, saving model to best_model_fold3.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 2s/step - accuracy: 0.6244 - loss: 1.2150 - val_accuracy: 0.8725 - val_loss: 0.4346 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8903 - loss: 0.3504\n",
      "Epoch 2: val_loss improved from 0.43461 to 0.24112, saving model to best_model_fold3.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 2s/step - accuracy: 0.8904 - loss: 0.3502 - val_accuracy: 0.9232 - val_loss: 0.2411 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9233 - loss: 0.2295\n",
      "Epoch 3: val_loss improved from 0.24112 to 0.20629, saving model to best_model_fold3.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 2s/step - accuracy: 0.9233 - loss: 0.2294 - val_accuracy: 0.9395 - val_loss: 0.2063 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9434 - loss: 0.1693\n",
      "Epoch 4: val_loss improved from 0.20629 to 0.18060, saving model to best_model_fold3.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 2s/step - accuracy: 0.9434 - loss: 0.1693 - val_accuracy: 0.9518 - val_loss: 0.1806 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9646 - loss: 0.1120\n",
      "Epoch 5: val_loss did not improve from 0.18060\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 2s/step - accuracy: 0.9646 - loss: 0.1120 - val_accuracy: 0.9412 - val_loss: 0.1971 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9588 - loss: 0.1184\n",
      "Epoch 6: val_loss improved from 0.18060 to 0.17364, saving model to best_model_fold3.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 2s/step - accuracy: 0.9587 - loss: 0.1185 - val_accuracy: 0.9469 - val_loss: 0.1736 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9641 - loss: 0.1006\n",
      "Epoch 7: val_loss improved from 0.17364 to 0.13890, saving model to best_model_fold3.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 2s/step - accuracy: 0.9641 - loss: 0.1007 - val_accuracy: 0.9583 - val_loss: 0.1389 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9713 - loss: 0.0847\n",
      "Epoch 8: val_loss improved from 0.13890 to 0.10996, saving model to best_model_fold3.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 2s/step - accuracy: 0.9713 - loss: 0.0848 - val_accuracy: 0.9657 - val_loss: 0.1100 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9625 - loss: 0.0931\n",
      "Epoch 9: val_loss did not improve from 0.10996\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 2s/step - accuracy: 0.9625 - loss: 0.0931 - val_accuracy: 0.9551 - val_loss: 0.1634 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9743 - loss: 0.0740\n",
      "Epoch 10: val_loss did not improve from 0.10996\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 2s/step - accuracy: 0.9743 - loss: 0.0740 - val_accuracy: 0.9681 - val_loss: 0.1345 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Fold 3 done. Test acc: 0.9620, Test loss: 0.1176\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759408200.837667      19 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6270 - loss: 1.1962\n",
      "Epoch 1: val_loss improved from inf to 0.37355, saving model to best_model_fold4.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 2s/step - accuracy: 0.6278 - loss: 1.1934 - val_accuracy: 0.8758 - val_loss: 0.3735 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8995 - loss: 0.3133\n",
      "Epoch 2: val_loss improved from 0.37355 to 0.21713, saving model to best_model_fold4.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 2s/step - accuracy: 0.8995 - loss: 0.3133 - val_accuracy: 0.9346 - val_loss: 0.2171 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9269 - loss: 0.2252\n",
      "Epoch 3: val_loss improved from 0.21713 to 0.18119, saving model to best_model_fold4.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 2s/step - accuracy: 0.9269 - loss: 0.2250 - val_accuracy: 0.9379 - val_loss: 0.1812 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9437 - loss: 0.1784\n",
      "Epoch 4: val_loss improved from 0.18119 to 0.12697, saving model to best_model_fold4.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 2s/step - accuracy: 0.9437 - loss: 0.1784 - val_accuracy: 0.9575 - val_loss: 0.1270 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9581 - loss: 0.1224\n",
      "Epoch 5: val_loss improved from 0.12697 to 0.10549, saving model to best_model_fold4.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 2s/step - accuracy: 0.9581 - loss: 0.1224 - val_accuracy: 0.9665 - val_loss: 0.1055 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9531 - loss: 0.1356\n",
      "Epoch 6: val_loss did not improve from 0.10549\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 2s/step - accuracy: 0.9531 - loss: 0.1357 - val_accuracy: 0.9534 - val_loss: 0.1434 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9651 - loss: 0.1218\n",
      "Epoch 7: val_loss did not improve from 0.10549\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9651 - loss: 0.1217 - val_accuracy: 0.9420 - val_loss: 0.1883 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9658 - loss: 0.1070\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.10549\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 2s/step - accuracy: 0.9658 - loss: 0.1070 - val_accuracy: 0.9542 - val_loss: 0.1345 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9786 - loss: 0.0679\n",
      "Epoch 9: val_loss improved from 0.10549 to 0.08500, saving model to best_model_fold4.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 2s/step - accuracy: 0.9786 - loss: 0.0679 - val_accuracy: 0.9714 - val_loss: 0.0850 - learning_rate: 2.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9852 - loss: 0.0472\n",
      "Epoch 10: val_loss improved from 0.08500 to 0.08457, saving model to best_model_fold4.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 2s/step - accuracy: 0.9852 - loss: 0.0472 - val_accuracy: 0.9722 - val_loss: 0.0846 - learning_rate: 2.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Fold 4 done. Test acc: 0.9806, Test loss: 0.0714\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759411729.622534      19 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/efficientnetb0_1/block2b_drop_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6332 - loss: 1.1872\n",
      "Epoch 1: val_loss improved from inf to 0.38789, saving model to best_model_fold5.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 2s/step - accuracy: 0.6340 - loss: 1.1846 - val_accuracy: 0.8725 - val_loss: 0.3879 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8873 - loss: 0.3441\n",
      "Epoch 2: val_loss improved from 0.38789 to 0.15126, saving model to best_model_fold5.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 2s/step - accuracy: 0.8874 - loss: 0.3440 - val_accuracy: 0.9493 - val_loss: 0.1513 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9243 - loss: 0.2343\n",
      "Epoch 3: val_loss improved from 0.15126 to 0.13185, saving model to best_model_fold5.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 2s/step - accuracy: 0.9243 - loss: 0.2343 - val_accuracy: 0.9542 - val_loss: 0.1319 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9547 - loss: 0.1445\n",
      "Epoch 4: val_loss improved from 0.13185 to 0.11246, saving model to best_model_fold5.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 2s/step - accuracy: 0.9547 - loss: 0.1446 - val_accuracy: 0.9608 - val_loss: 0.1125 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9581 - loss: 0.1178\n",
      "Epoch 5: val_loss did not improve from 0.11246\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 2s/step - accuracy: 0.9581 - loss: 0.1179 - val_accuracy: 0.9583 - val_loss: 0.1220 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9629 - loss: 0.1070\n",
      "Epoch 6: val_loss improved from 0.11246 to 0.11114, saving model to best_model_fold5.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 2s/step - accuracy: 0.9629 - loss: 0.1071 - val_accuracy: 0.9681 - val_loss: 0.1111 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9665 - loss: 0.0958\n",
      "Epoch 7: val_loss improved from 0.11114 to 0.09568, saving model to best_model_fold5.h5\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 2s/step - accuracy: 0.9665 - loss: 0.0958 - val_accuracy: 0.9714 - val_loss: 0.0957 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9718 - loss: 0.0812\n",
      "Epoch 8: val_loss did not improve from 0.09568\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 2s/step - accuracy: 0.9717 - loss: 0.0813 - val_accuracy: 0.9632 - val_loss: 0.1363 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9706 - loss: 0.0879\n",
      "Epoch 9: val_loss did not improve from 0.09568\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 2s/step - accuracy: 0.9706 - loss: 0.0880 - val_accuracy: 0.9567 - val_loss: 0.1387 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9697 - loss: 0.0879\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.09568\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 2s/step - accuracy: 0.9696 - loss: 0.0880 - val_accuracy: 0.9649 - val_loss: 0.1071 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Fold 5 done. Test acc: 0.9537, Test loss: 0.1202\n",
      "\n",
      "K-Fold run complete. Report saved to: kfold_full_report.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0, VGG16, ResNet50\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_pre\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_pre\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as res_pre\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input, BatchNormalization, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------\n",
    "# User params (modify as needed)\n",
    "# -------------------------\n",
    "BASE_PATH = '/kaggle/input/mango7200-12/MangoMerged'  \n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32                 \n",
    "NUM_FOLDS = 5\n",
    "EPOCHS = 10\n",
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "PDF_REPORT = \"kfold_full_report.pdf\"\n",
    "\n",
    "# -------------------------\n",
    "# Reproducibility\n",
    "# -------------------------\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# TPU / Strategy detection\n",
    "# -------------------------\n",
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    print(\"Running on TPU:\", resolver.cluster_spec().as_dict())\n",
    "except Exception as e:\n",
    "    # Fallback to MirroredStrategy (multi-GPU) if available, else default strategy\n",
    "    try:\n",
    "        gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        if gpus:\n",
    "            strategy = tf.distribute.MirroredStrategy()\n",
    "            print(\"Running on MirroredStrategy with GPUs:\", gpus)\n",
    "        else:\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "            print(\"Running on default strategy (CPU).\")\n",
    "    except:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        print(\"Running on default strategy (CPU).\")\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "# Scale batch size for distributed strategy (TPU/GPU)\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * max(1, strategy.num_replicas_in_sync)\n",
    "\n",
    "# -------------------------\n",
    "# Helper: collect filepaths and one-hot labels\n",
    "# -------------------------\n",
    "def collect_filepaths_and_labels(base_dir):\n",
    "    class_names = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
    "    class_to_index = {c: i for i, c in enumerate(class_names)}\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    for cls in class_names:\n",
    "        cls_dir = os.path.join(base_dir, cls)\n",
    "        for fname in os.listdir(cls_dir):\n",
    "            if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "                filepaths.append(os.path.join(cls_dir, fname))\n",
    "                labels.append(class_to_index[cls])\n",
    "    filepaths = np.array(filepaths)\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    return filepaths, labels, class_names\n",
    "\n",
    "# -------------------------\n",
    "# Build dataset mapping functions\n",
    "# -------------------------\n",
    "def decode_and_resize(path, label):\n",
    "    # path: string scalar tensor of filepath\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
    "    image.set_shape([None, None, 3])\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = tf.cast(image, tf.float32)  # leave in 0-255 float; model lambdas will preprocess\n",
    "    return image, label\n",
    "\n",
    "def one_hot_label(image, label, num_classes):\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "def prepare_dataset(filepaths, labels, num_classes, is_training=True, batch_size=GLOBAL_BATCH_SIZE):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
    "    if is_training:\n",
    "        ds = ds.shuffle(buffer_size=len(filepaths), seed=SEED)\n",
    "    ds = ds.map(decode_and_resize, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.map(lambda x, y: one_hot_label(x, y, num_classes), num_parallel_calls=AUTOTUNE)\n",
    "    if is_training:\n",
    "        ds = ds.repeat()  # we'll pass steps_per_epoch to fit\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# -------------------------\n",
    "# Model builder (inside strategy scope)\n",
    "# -------------------------\n",
    "def build_model(num_classes):\n",
    "    input_shape = IMG_SIZE + (3,)\n",
    "    inputs = Input(shape=input_shape, dtype=tf.float32)\n",
    "\n",
    "    # Preprocess for each model separately (Lambda layers)\n",
    "    eff_input = Lambda(lambda x: eff_pre(x), name=\"eff_pre\")(inputs)\n",
    "    vgg_input = Lambda(lambda x: vgg_pre(x), name=\"vgg_pre\")(inputs)\n",
    "    res_input = Lambda(lambda x: res_pre(x), name=\"res_pre\")(inputs)\n",
    "\n",
    "    # Base models\n",
    "    effnet_base = EfficientNetB0(weights=\"imagenet\", include_top=False)\n",
    "    vgg16_base = VGG16(weights=\"imagenet\", include_top=False)\n",
    "    resnet_base = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "    # Freeze base models for transfer learning\n",
    "    for base in (effnet_base, vgg16_base, resnet_base):\n",
    "        base.trainable = False\n",
    "\n",
    "    # Extract features\n",
    "    eff_features = effnet_base(eff_input)\n",
    "    vgg_features = vgg16_base(vgg_input)\n",
    "    res_features = resnet_base(res_input)\n",
    "\n",
    "    feat1 = GlobalAveragePooling2D()(eff_features)\n",
    "    feat2 = GlobalAveragePooling2D()(vgg_features)\n",
    "    feat3 = GlobalAveragePooling2D()(res_features)\n",
    "\n",
    "    merged = Concatenate()([feat1, feat2, feat3])\n",
    "\n",
    "    x = Dense(512, activation=\"relu\")(merged)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# -------------------------\n",
    "# Main K-Fold flow\n",
    "# -------------------------\n",
    "def run_kfold(base_path, num_folds=NUM_FOLDS, epochs=EPOCHS):\n",
    "    # collect train + val together as \"X_all\"\n",
    "    train_dir = os.path.join(base_path, \"train\")\n",
    "    val_dir = os.path.join(base_path, \"val\")\n",
    "    test_dir = os.path.join(base_path, \"test\")\n",
    "\n",
    "    # Collect filepaths & labels for train+val\n",
    "    train_files, train_labels, class_names_train = collect_filepaths_and_labels(train_dir)\n",
    "    val_files, val_labels, class_names_val = collect_filepaths_and_labels(val_dir)\n",
    "\n",
    "    # sanity: class names should match\n",
    "    if class_names_train != class_names_val:\n",
    "        print(\"Warning: train and val class order differ. Proceeding with union & sorted classes.\")\n",
    "    # Use sorted union of class names (to ensure consistent indexing)\n",
    "    all_classes = sorted(list(set(class_names_train) | set(class_names_val)))\n",
    "    class_to_idx = {c: i for i, c in enumerate(all_classes)}\n",
    "    num_classes = len(all_classes)\n",
    "    print(\"Detected classes:\", all_classes)\n",
    "\n",
    "    # Re-map train/val labels to this unified index\n",
    "    def remap(filepaths, labels, original_class_names):\n",
    "        remapped = []\n",
    "        for p, lbl in zip(filepaths, labels):\n",
    "            # derive class name from parent folder\n",
    "            cls = os.path.basename(os.path.dirname(p))\n",
    "            remapped.append(class_to_idx[cls])\n",
    "        return np.array(remapped, dtype=np.int32)\n",
    "\n",
    "    train_labels_m = remap(train_files, train_labels, class_names_train)\n",
    "    val_labels_m = remap(val_files, val_labels, class_names_val)\n",
    "\n",
    "    X_all_files = np.concatenate([train_files, val_files], axis=0)\n",
    "    y_all_labels = np.concatenate([train_labels_m, val_labels_m], axis=0)\n",
    "\n",
    "    # Test set\n",
    "    test_files, test_labels, class_names_test = collect_filepaths_and_labels(test_dir)\n",
    "    # Remap test labels to unified classes\n",
    "    test_labels_m = []\n",
    "    for p, lbl in zip(test_files, test_labels):\n",
    "        cls = os.path.basename(os.path.dirname(p))\n",
    "        test_labels_m.append(class_to_idx.get(cls, -1))\n",
    "    test_labels_m = np.array(test_labels_m, dtype=np.int32)\n",
    "    # filter out any test items not in class mapping (shouldn't happen)\n",
    "    valid_mask = test_labels_m >= 0\n",
    "    test_files = test_files[valid_mask]\n",
    "    test_labels_m = test_labels_m[valid_mask]\n",
    "\n",
    "    # K-Fold on indices\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    fold_train_acc, fold_train_loss = [], []\n",
    "    fold_val_acc, fold_val_loss = [], []\n",
    "    fold_test_acc, fold_test_loss = [], []\n",
    "    fold_class_reports = []\n",
    "\n",
    "    # PDF for all outputs\n",
    "    with PdfPages(PDF_REPORT) as pdf:\n",
    "        fold_no = 1\n",
    "        for train_idx, val_idx in kf.split(X_all_files):\n",
    "            print(f\"\\n===== Fold {fold_no} =====\")\n",
    "            K.clear_session()\n",
    "            gc.collect()\n",
    "\n",
    "            # Slice filepaths and labels for this fold\n",
    "            train_files_fold = X_all_files[train_idx]\n",
    "            train_labels_fold = y_all_labels[train_idx]\n",
    "            val_files_fold = X_all_files[val_idx]\n",
    "            val_labels_fold = y_all_labels[val_idx]\n",
    "\n",
    "            # Build tf.data datasets (note: train dataset .repeat() is handled inside prepare_dataset)\n",
    "            train_ds = prepare_dataset(train_files_fold, train_labels_fold, num_classes,\n",
    "                                       is_training=True, batch_size=GLOBAL_BATCH_SIZE)\n",
    "            val_ds = prepare_dataset(val_files_fold, val_labels_fold, num_classes,\n",
    "                                     is_training=False, batch_size=GLOBAL_BATCH_SIZE)\n",
    "            test_ds = prepare_dataset(test_files, test_labels_m, num_classes,\n",
    "                                      is_training=False, batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "            # steps per epoch (since train_ds repeats)\n",
    "            steps_per_epoch = math.ceil(len(train_files_fold) / GLOBAL_BATCH_SIZE)\n",
    "            validation_steps = math.ceil(len(val_files_fold) / GLOBAL_BATCH_SIZE)\n",
    "            test_steps = math.ceil(len(test_files) / GLOBAL_BATCH_SIZE)\n",
    "\n",
    "            # Build model inside strategy scope\n",
    "            with strategy.scope():\n",
    "                model = build_model(num_classes)\n",
    "\n",
    "            # Callbacks\n",
    "            fold_ckpt = f\"best_model_fold{fold_no}.h5\"\n",
    "            callbacks = [\n",
    "                ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, verbose=1),\n",
    "                EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1),\n",
    "                ModelCheckpoint(fold_ckpt, monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "            ]\n",
    "\n",
    "            # Fit\n",
    "            history = model.fit(train_ds,\n",
    "                                epochs=epochs,\n",
    "                                steps_per_epoch=steps_per_epoch,\n",
    "                                validation_data=val_ds,\n",
    "                                validation_steps=validation_steps,\n",
    "                                callbacks=callbacks,\n",
    "                                verbose=1)\n",
    "\n",
    "            # save history metrics\n",
    "            fold_train_acc.append(history.history.get('accuracy', [None])[-1])\n",
    "            fold_train_loss.append(history.history.get('loss', [None])[-1])\n",
    "            fold_val_acc.append(history.history.get('val_accuracy', [None])[-1])\n",
    "            fold_val_loss.append(history.history.get('val_loss', [None])[-1])\n",
    "\n",
    "            # Evaluate on test set\n",
    "            test_res = model.evaluate(test_ds, steps=test_steps, verbose=0)\n",
    "            test_loss, test_acc = test_res[0], test_res[1] if len(test_res) > 1 else (None, None)\n",
    "            fold_test_acc.append(test_acc)\n",
    "            fold_test_loss.append(test_loss)\n",
    "\n",
    "            # Predictions for classification report\n",
    "            y_pred_probs = model.predict(test_ds, steps=test_steps, verbose=0)\n",
    "            y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "            y_true_labels = test_labels_m  # numeric labels already\n",
    "\n",
    "            report = classification_report(y_true_labels, y_pred_labels, target_names=all_classes, digits=4, zero_division=0)\n",
    "            fold_class_reports.append(report)\n",
    "\n",
    "            # Confusion matrix (use correct arrays)\n",
    "            cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "            # Save confusion matrices with multiple color maps into the single PDF\n",
    "            colormaps = {\n",
    "                \"blue\": \"Blues\",\n",
    "                \"red\": \"Reds\",\n",
    "                \"green\": \"Greens\",\n",
    "                \"magenta\": \"magma\",\n",
    "                \"viridis\": \"viridis\"\n",
    "            }\n",
    "            for color_name, cmap_name in colormaps.items():\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=cmap_name,\n",
    "                            xticklabels=all_classes, yticklabels=all_classes)\n",
    "                plt.xlabel(\"Predicted\")\n",
    "                plt.ylabel(\"True\")\n",
    "                plt.title(f\"Fold {fold_no} - Confusion Matrix ({color_name})\")\n",
    "                plt.tight_layout()\n",
    "                pdf.savefig()\n",
    "                plt.close()\n",
    "\n",
    "            # Accuracy & Loss plots\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.plot(history.history.get('accuracy', []), label=\"Train Acc\")\n",
    "            plt.plot(history.history.get('val_accuracy', []), label=\"Val Acc\")\n",
    "            plt.title(f\"Fold {fold_no} Accuracy\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.plot(history.history.get('loss', []), label=\"Train Loss\")\n",
    "            plt.plot(history.history.get('val_loss', []), label=\"Val Loss\")\n",
    "            plt.title(f\"Fold {fold_no} Loss\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "            # Classification report page\n",
    "            fig, ax = plt.subplots(figsize=(8.5, 11))\n",
    "            ax.axis(\"off\")\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            ax.text(0, 1, f\"Classification Report - Fold {fold_no}\\nGenerated: {timestamp}\\n\\n{report}\",\n",
    "                    fontsize=9, family=\"monospace\", va=\"top\")\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "            print(f\"Fold {fold_no} done. Test acc: {test_acc:.4f}, Test loss: {test_loss:.4f}\")\n",
    "            fold_no += 1\n",
    "\n",
    "        # After all folds: summary page\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.axis('off')\n",
    "        summary_text = \"Fold | Train Acc | Train Loss | Val Acc | Val Loss | Test Acc | Test Loss\\n\"\n",
    "        summary_text += \"-\"*90 + \"\\n\"\n",
    "        for i in range(len(fold_train_acc)):\n",
    "            summary_text += (f\"{i+1:>4} | \"\n",
    "                             f\"{(fold_train_acc[i] if fold_train_acc[i] is not None else float('nan')):.4f} | \"\n",
    "                             f\"{(fold_train_loss[i] if fold_train_loss[i] is not None else float('nan')):.4f} | \"\n",
    "                             f\"{(fold_val_acc[i] if fold_val_acc[i] is not None else float('nan')):.4f} | \"\n",
    "                             f\"{(fold_val_loss[i] if fold_val_loss[i] is not None else float('nan')):.4f} | \"\n",
    "                             f\"{(fold_test_acc[i] if fold_test_acc[i] is not None else float('nan')):.4f} | \"\n",
    "                             f\"{(fold_test_loss[i] if fold_test_loss[i] is not None else float('nan')):.4f}\\n\")\n",
    "        ax.text(0, 1, \"K-Fold Summary Metrics\\n\\n\" + summary_text, fontsize=10, family=\"monospace\", va=\"top\")\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # Aggregate stats page\n",
    "        metrics = {\n",
    "            \"Train Acc\": [v for v in fold_train_acc if v is not None],\n",
    "            \"Train Loss\": [v for v in fold_train_loss if v is not None],\n",
    "            \"Val Acc\": [v for v in fold_val_acc if v is not None],\n",
    "            \"Val Loss\": [v for v in fold_val_loss if v is not None],\n",
    "            \"Test Acc\": [v for v in fold_test_acc if v is not None],\n",
    "            \"Test Loss\": [v for v in fold_test_loss if v is not None],\n",
    "        }\n",
    "\n",
    "        stats_text = \"Metric        | Mean     | Std      | Min      | Max\\n\"\n",
    "        stats_text += \"-\"*55 + \"\\n\"\n",
    "        for name, values in metrics.items():\n",
    "            if len(values) == 0:\n",
    "                stats_text += f\"{name:<12} | {'nan':>7} | {'nan':>7} | {'nan':>7} | {'nan':>7}\\n\"\n",
    "            else:\n",
    "                stats_text += f\"{name:<12} | {np.mean(values):.4f} | {np.std(values):.4f} | {np.min(values):.4f} | {np.max(values):.4f}\\n\"\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.axis(\"off\")\n",
    "        ax.text(0, 1, \"Aggregate K-Fold Statistics\\n\\n\" + stats_text, fontsize=10, family=\"monospace\", va=\"top\")\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"\\nK-Fold run complete. Report saved to: {PDF_REPORT}\")\n",
    "\n",
    "# -------------------------\n",
    "# Run\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_kfold(BASE_PATH, num_folds=NUM_FOLDS, epochs=EPOCHS)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8352290,
     "sourceId": 13180057,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17585.480289,
   "end_time": "2025-10-02T14:26:23.842250",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-02T09:33:18.361961",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
